# QAPipeline-using-LLMs

This repository contains a Python script for processing books and generating summaries, questions, and answers using large language models (LLMs).

## Overview

The "qa-llamacpp-pipeline" notebook contains all the code required to execute the tasks. The pipeline is designed to allow you to easily extract meaningful insights from books PDF files.

## Getting Started

To get started with the QAPipeline using LLMs, follow these steps:

1. Clone this repository to kaggle or your local machine.
2. Open the "qa-llamacpp-pipeline" notebook.
3. Run the notebook cells to execute the tasks and generate summaries, questions, and answers.

## Acknowledgments

- This project utilizes the compute power generously provided by Kaggle and open large language models available on huggingface using llamacpp.